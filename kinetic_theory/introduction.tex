The kinetic theory of gases is a microscopic theory that describes the behaviour gases on the molecular level. A system of $N$ particles is fully described by the $3N$ momentum components combined with the $3N$ spatial coordinates. Together, this forms a $6N$ dimensional phase space where each point represents the state of the system. In this chapter we will discuss this formalism and how such a system evolves through time by deriving the Boltzmann equation. We will derive some results that will be implemented in the Direct Simulation Monte Carlo model in chapter \ref{chap:dsmc}.

\section{The distribution function}
A point in the phase space describes what is called a \textit{microstate} and contains a massive amount of information. With this point, you would know the position and velocity to every particle in the entire system. In a liter of ideal gas under standard pressure, the number of particles is of order $10^{22}$ \cite{garcia2000numerical}, so if we represent each of these $6N$ coordinates as an 8 byte \textit{double} on a computer, this would require more than $10^{11}$ terabytes of memory. However, this approach is very inconvenient and not at all necessary. The really interesting properties in a system are the macroscopic ones, like energy, temperature, pressure, volume, velocity, etc. For example, the total energy in a gas consisting of $N$ particles is calculated as
\begin{align*}
	E = \sum_{i=1}^N \frac{1}{2} m_i v_i^2 + V(\vec q),
\end{align*}
where $m_i$ is the mass of particle $i$, $v_i$ is its scalar velocity and $V(\vec q)$ is the total potential energy in the system depending on the full $3N$-dimensional spatial coordinate $\vec q$. What happens if we switch two particles, say particle $i$ and $j$? If particle $i$ had velocity $\vec v_i = \vec u$ and particle $j$ had some other velocity $\vec v_j = \vec w$, we could quickly swap them so that $\vec v_i = w$ and $\vec v_j = u$ (theoretically of course, this would be a difficult task in an experiment). If their masses are identical, the total energy would not change, but since \textit{we} know that we interchanged the two particles, so we could want to count this as another microstate. We could paint the particles in different colors, or just label them with their own unique number. However, in a real, monoatomic gas, we can't really tell the difference if particle $i$ and $j$ secretly agreed to switch places. This would not count as different microstates, the system remains exactly the same. We say that the particles are \textit{indistinguishable}.\\
If we instead increase the velocity of particle $i$, we can reduce some another particle $j$'s velocity to keep the total energy constant. Even though the macroscopic property \textit{energy} is unchanged, there is a (theoretically) measureable difference between these two states. The set of all microstates that have the same macroscopic state variables (a \textit{macrostate}) forms an ensemble of systems. In a typical system, the number of microstates in a macrostate is so huge that the phase space points can be described by a continous density function $f_N(\vec p, \vec q, t)$ without losing any important information \cite{mcquarrie1973statistical}. The input parameters are the $3N$ momentum components, the $3N$ spatial coordinates plus time. This function is often called a \textit{distribution function}, and is commonly just written as $f_N(p, q, t)$. The distribution function is normalized so that
\begin{align}
	\int f_N(p, q, t) dpdq = 1,
\end{align}
where $dpdq=dp_1dp_2...dq_{3N}$ is the $6N$ dimensional phase space volume element. 

\subsection{Ensemble averages}
Given the distribution function $f_N$, we can calculate any ensemble average (which will be the measurable, macroscopic properties of the system) by interpreting $f_N$ as a probability distribution that gives the probability of finding a particle at position $\vec r + d\vec r$ with velocity in the range $\vec v + d\vec v$ at the time $t$. We can then use the standard expectation value expression to calculate a macroscopic property $A(t)$
\begin{align}
	\langle A(t) \rangle = \int A(p, q, t)f_N(p, q, t)dpdq.
\end{align}
This could for example be the total energy
\begin{align}
	\langle E(t) \rangle &= \int E(p, q, t)f_N(p, q, t)dpdq \\
	&= \int \left(V(q) + \sum_{i=0}^N \frac{\vec p_i^2}{2m_i} \right)f_N(p, q, t)dpdq,
\end{align}
where $\vec p_i$ is particle $i$'s momentum vector. Any other quantity of interest can in principle be measured in the same way. 
\subsection{Ergodicity}

\section{Liouville equation}
The time evolution of the particles, and hence the phase point, is controlled by the equations of motion determined by the system. The distribution function itself will also evolve through time, following some sort of equation of motion. By conservation of phase points, one can derive the Liouville equation
\begin{align}
	\dpart{f_N}{t} + \{H, f_N\} = 0,
\end{align}
where $H$ is the Hamiltonian of the system and $\{,\}$ denotes the Poisson bracket
\begin{align}
	\{A,B\} = \sum_\alpha\left( \dpart{A}{\vec q_\alpha}\cdot\dpart{B}{\vec p_\alpha} - \dpart{B}{\vec q_\alpha}\cdot\dpart{A}{\vec p_\alpha}\right).
\end{align}
 Liouville's equation tells us how the system will evolve and is often referred to as the most fundamental equation of statistical mechanics\cite{mcquarrie1973statistical}. 
